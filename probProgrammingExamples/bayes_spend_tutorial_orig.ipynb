{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Bayesian Modelling in Real life\n",
    "\n",
    "This notebook was created for PyData NYC 2018.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from theano import shared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "## Campaign spend data\n",
    "\n",
    "This data comes from 13K digital marketing campaigns that were run since 2016.  Besides business ID, we have a set of variables that will be important to the model.  \n",
    "\n",
    "billed_amount : The amount billed for the campaign.  This is based on real data, but is not itself real.  Privacy issues and all that.\n",
    "\n",
    "log_billed_amount : The log of billed_amount.  Typically, spend amounts are log-normally distributed.  There's a small number of high spenders, and a large number of low spenders.\n",
    "\n",
    "product : The products we'll be focused on. They are as follows:\n",
    "    - Display = Display advertising, like you might see on a website\n",
    "    - SEM = Search Engine Marketing, dealing with \"sponsored\" search results in Google and Bing\n",
    "    - SEO = Search Engine Optimization, general name for services that aim to increase \"organic\" traffic, or traffic outside of paid services\n",
    "    - Social Ads = Advertising on social networks, specifically Facebook and Instagram\n",
    "    - Email = Direct email advertising, like you might get in your inbox.\n",
    "    \n",
    "size : Size of the company.  We have grouped this into four categories: Less than 50 employees, between 50 and 100,  more than 100 and \"unavailable\".  Unavailable just means we were unable to capture this information.\n",
    "\n",
    "region : The high-level US region of the company headquarters: Northeast, South, Midwest or West."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in data\n",
    "campaign_data = pd.read_csv('spend_data_distribute_short.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial descriptives\n",
    "We run these just so we have a sense of what our data looks like.  For this tutorial, we will be focusing on Product and Region, so we'll pay close attention to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrs = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "clr_dict = dict(zip(campaign_data['product'].unique(), clrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAD8CAYAAABO3GKQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAESxJREFUeJzt3X+MZWV9x/H3RxYEXLoYFhpAZEApKKC4u6JYfirxJ4VaSZBgA1a7arG01TaS0CjWRqk0EkURt00rjVa2kkhQIyWKW+MPxFlYWBYBUZeiaGGt8nNZBb79Yw7pdXZ25u7uPPdeZt6vZDL3Puc553yfk8t89nnuuZdUFZIktfK0YRcgSZrbDBpJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkpoyaCRJTRk0kqSmFgy7gFGwePHiGhsbG3YZkvSUsnr16g1VtedM/QwaYGxsjPHx8WGXIUlPKUnu6qefS2eSpKYMGklSUwaNJKkpg0aS1JRBI0lqyqCRJDVl0EiSmjJoJElNGTSSpKb8ZgDg3rse5BNvv3ZWj3n2pS+f1eNJ0lOVMxpJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkpoa+aBJcl6SdUluTrImyUuSrEpye/d8TZIrevovT3Jb93N9kqOHWb8kzXcj/TmaJEcBJwFLqmpTksXATt3mM6pqfFL/k4C3AUdX1YYkS4ArkxxZVT8faPGSJGD0ZzR7AxuqahNAVW2oqnum6f8e4G+qakPX/wbgMuDs5pVKkqY06kFzDbBfkjuSXJLkuJ5tn+1ZOruwazsUWD3pGONduyRpCEZ66ayqHkqyFDgGOAFYmeTcbvNmS2dbEKA2a0yWA8sBnrlwr1mqWJI02UgHDUBVPQ6sAlYlWQucOU33W4GlQO8Xly3p2icfdwWwAuDZex68WRBJkmbHSC+dJTk4yUE9TUcAd02zy4eBf0iyR7f/EcBZwCXNipQkTWvUZzQLgYuT7A48BtzJxHLXFUy8R7Ox67ehqk6sqquS7At8O0kBDwJvqqqfDaN4SdKIB01VrQZeNsWm46fZ55PAJ1vVJEnaOiO9dCZJeuozaCRJTRk0kqSmDBpJUlMGjSSpKYNGktTUSN/ePCh77b8bZ1/68mGXIUlzkjMaSVJTBo0kqSmDRpLUlEEjSWrKoJEkNWXQSJKaMmgkSU0ZNJKkpgwaSVJTBo0kqSmDRpLUlEEjSWrKoJEkNWXQSJKaMmgkSU0ZNJKkpgwaSVJTBo0kqSmDRpLUlEEjSWrKoJEkNbVg2AWMgkdvWcf3D3nesMt4Snrebd8fdgmSRpwzGklSUwaNJKkpg0aS1JRBI0lqyqCRJDVl0EiSmhp60CR5PMmanp9zZ+m43+5+jyW5ZTaOKUnaeqPwOZqNVXXEbB+0ql4228eUJG29oc9otiTJ+iQfTPKdJONJliT5zyQ/TPL2rs/CJF9LckOStUlO6dn/oeFVL0l60ijMaHZJsqbn+YeqamX3+O6qOirJRcCngd8HdgbWAZcCjwKvr6oHkiwGrktyVVXVAOuXJE1jFIJmuqWzq7rfa4GFVfUg8GCSR5PsDjwMfDDJscATwL7A7wI/n+mkSZYDywH2XjAKl0GS5qZR/wu7qfv9RM/jJ58vAM4A9gSWVtVvkqxnYsYzo6paAawAOGznXZwBSVIjI/seTZ8WAfd2IXMCsP+wC5Ik/bZRmNFMfo/m6qrq9xbnzwJfTDIOrAFum/XqJEnbZehBU1U7bKF9rOfxp5m4GWCzbcBRW9h/Yfd7PXDY9tYpSdo2T/WlM0nSiDNoJElNGTSSpKYMGklSUwaNJKmpod91Ngp2PuxQnjc+PuwyJGlOckYjSWrKoJEkNWXQSJKaMmgkSU0ZNJKkpgwaSVJTBo0kqSmDRpLUlEEjSWrKoJEkNWXQSJKaMmgkSU0ZNJKkpgwaSVJTBo0kqSmDRpLUlEEjSWrKoJEkNWXQSJKaMmgkSU0ZNJKkphYMu4BRsO4X6zj8ssOHXYZ6rD1z7bBLkDRLnNFIkpoyaCRJTRk0kqSmDBpJUlMGjSSpKYNGktTUSAdNkvOSrEtyc5I1SV6SZFWS27vna5Jc0fU9P0kleW7P/n/VtS0b3igkaX4b2c/RJDkKOAlYUlWbkiwGduo2n1FV41PsthZ4I/D33fNTgVubFytJ2qJRntHsDWyoqk0AVbWhqu6ZYZ8rgVMAkhwI3A/c17RKSdK0RjlorgH2S3JHkkuSHNez7bM9S2cX9rQ/ANyd5DDgdGDlIAuWJG1uZJfOquqhJEuBY4ATgJVJzu02b2npDOByJpbPXgW8AnjzVJ2SLAeWA+y4x46zWbokqcfIBg1AVT0OrAJWJVkLnNnHbl8ELgTGq+qBJFs69gpgBcAuB+xSs1KwJGkzIxs0SQ4GnqiqH3RNRwB3AYdNt19VbUzyHuCOxiVKkvowskEDLAQuTrI78BhwJxNLXVcw8R7Nxq7fhqo6sXfHqrp8oJVKkrZoZIOmqlYDL5ti0/Fb6H/+Ftqn7C9JGoxRvutMkjQHGDSSpKYMGklSUwaNJKkpg0aS1JRBI0lqamRvbx6kQ/c4lPEzt/SNNpKk7eGMRpLUlEEjSWrKoJEkNWXQSJKaMmgkSU0ZNJKkpgwaSVJTBo0kqSmDRpLUlEEjSWrKoJEkNWXQSJKaMmgkSU0ZNJKkpgwaSVJTBo0kqSmDRpLUlEEjSWrKoJEkNWXQSJKaMmgkSU0tGHYBI+GeG+H8RcOuQoN0/v3DrkCaN5zRSJKaMmgkSU0ZNJKkpgwaSVJTBo0kqSmDRpLU1IxBk+S8JOuS3JxkTZKXbO1JkixL8rEZ+hyf5EvTbP9okp8m2WLNSdYnWby19UmS2pn2czRJjgJOApZU1abuj/hOW3uSqhoHxretROjC5fXA3cCxwKptPZYkabBmmtHsDWyoqk0AVbWhqu4BSPKKJDcmWZvkX5I8vWt/cZJvJ7kpyfVJduudrSQ5stt+Y/f74D7qPAG4BfgkcPqTjUn2SHJNd6xPAenan5Hky10NtyQ5bSuviyRplswUNNcA+yW5I8klSY4DSLIz8GngtKo6nImZ0TuS7ASsBP6iql4InAhsnHTM24Bjq+pFwHuBD/ZR5+nA54AvACcl2bFrfx/wze5YVwHP7tpfDdxTVS+sqsOAq/s4hySpgWmDpqoeApYCy4H7gJVJzgIOBn5cVXd0XS9jYknrYOBnVfW9bv8HquqxSYddBHw+yS3ARcCh09XQhddrgSur6gHgu8Aru83HAp/pzvVl4Jdd+1rgxCT/kOSYqtrs+0aSLE8ynmT8vkdquhIkSdthxpsBqurxqlpVVe8D3gm8gW6JagoBZvqr/QHg691M4w+AnWfo/2omwmltkvXA0fQsn011vi4AlzIROB9K8t4p+qyoqmVVtWzPXbc0HEnS9po2aJIcnOSgnqYjgLuYWP4aS/Lcrv2Pgf/q2vdJ8uJu/92STL7hYBHw0+7xWX3UeDrw1qoaq6ox4ADglUl2Bb4BnNGd6zXAM7vH+wCPVNVngH8ElvRxHklSAzN9e/NC4OIkuwOPAXcCy6vq0SRvZmIJbAHwPeDSqvp198b7xUl2YeL9mRMnHfPDwGVJ3gVcO93JuzB5FfC2J9uq6uEk32RiNvR+4HNJbmAi6P6763Y4cGGSJ4DfAO+YYZySpEZS5fsTy/bZocaXLxx2GRok/zcB0nZLsrqqls3Uz28GkCQ1ZdBIkpoyaCRJTRk0kqSmDBpJUlMz3d48P+zzIjh/m7/zU5I0DWc0kqSmDBpJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkpoyaCRJTRk0kqSmDBpJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkpoyaCRJTRk0kqSmDBpJUlMGjSSpKYNGktSUQSNJamrBsAsYBWt/ej9j53552GVI0kCtv+B1AzmPMxpJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkppqFjRJHk+yJsm6JDcleVeSp3XbliX52DYed32SxbNbrSSplZafo9lYVUcAJNkL+HdgEfC+qhoHxhueW5I0IgaydFZV9wLLgXdmwvFJvgSQ5Lhu5rMmyY1Jduu2fyPJF5LcmuTSJ2dDvZJcmWR1N2ta3rW9JclFPX3+NMlHBjFOSdLmBvYeTVX9qDvfXpM2/TVwdjf7OQbY2LUfCbwbOBx4DvBHUxz2T6pqKbAMOCfJHsDlwMlJduz6vBn419kciySpf4O+GSBTtH0L+EiSc4Ddq+qxrv36qvpRVT0OfA44eop9z0lyE3AdsB9wUFU9DFwLnJTkEGDHqlq7WSHJ8iTjScYff+T+WRiaJGkqAwuaJAcCjwP39rZX1QXAW4FdgOu6cACoSYf4redJjgdOBI6qqhcCNwI7d5v/GTiLaWYzVbWiqpZV1bIddl20jaOSJM1kIF+qmWRP4FLg41VVSXq3PaebcaxNchRwCPAr4MgkBwB3AacBKyYddhHwy6p6pAunlz65oaq+m2Q/YAnwgoZDkyTNoOWMZpcnb28GvgpcA7x/in5/meSWbglsI/CVrv07wAXALcCPgS9M2u9qYEGSm4EPMLF81us/gG9V1S9nZTSSpG3SbEZTVTtMs20VsKp7/OeTt3cznkeq6rQp9h3refqaaUo4Grhomu2SpAGYc98MkGT3JHcw8Tmerw27Hkma70byf3zWO+PZhn1/BfzebNYjSdp2c25GI0kaLQaNJKkpg0aS1JRBI0lqaiRvBhi0w/ddxPgFrxt2GZI0JzmjkSQ1ZdBIkpoyaCRJTRk0kqSmDBpJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkppKVQ27hqFL8iBw+7DrGLLFwIZhFzFEjn9+jx+8Btsy/v2ras+ZOvldZxNur6plwy5imJKMz+dr4Pjn9/jBa9By/C6dSZKaMmgkSU0ZNBNWDLuAETDfr4Hj13y/Bs3G780AkqSmnNFIkpqaV0GT5NVJbk9yZ5Jzp9j+9CQru+3fTTI2+Crb6WP8xya5IcljSU4dRo2t9XEN3pXk1iQ3J/lakv2HUWcrfYz/7UnWJlmT5JtJnj+MOlua6Rr09Ds1SSWZU3ei9fEaOCvJfd1rYE2St273SatqXvwAOwA/BA4EdgJuAp4/qc+fAZd2j98IrBx23QMe/xjwAuDfgFOHXfOQrsEJwK7d43fMw9fA7/Q8Phm4eth1D/oadP12A74BXAcsG3bdA34NnAV8fDbPO59mNEcCd1bVj6rq18DlwCmT+pwCXNY9vgJ4RZIMsMaWZhx/Va2vqpuBJ4ZR4AD0cw2+XlWPdE+vA5414Bpb6mf8D/Q8fQYw197E7efvAMAHgA8Djw6yuAHod/yzaj4Fzb7A3T3Pf9K1Tdmnqh4D7gf2GEh17fUz/rlua6/BW4CvNK1osPoaf5Kzk/yQiT+05wyotkGZ8RokeRGwX1V9aZCFDUi//w28oVs+viLJftt70vkUNFPNTCb/a62fPk9Vc3ls/er7GiR5E7AMuLBpRYPV1/ir6hNV9RzgPcDfNq9qsKa9BkmeBlwEvHtgFQ1WP6+BLwJjVfUC4Kv8/yrPNptPQfMToDeZnwXcs6U+SRYAi4D/HUh17fUz/rmur2uQ5ETgPODkqto0oNoGYWtfA5cDf9i0osGb6RrsBhwGrEqyHngpcNUcuiFgxtdAVf2i53X/T8DS7T3pfAqa7wEHJTkgyU5MvNl/1aQ+VwFndo9PBa6t7t2xOaCf8c91M16DbtnkU0yEzL1DqLGlfsZ/UM/T1wE/GGB9gzDtNaiq+6tqcVWNVdUYE+/TnVxV48Mpd9b18xrYu+fpycD3t/usw74LYsB3XLwWuIOJuy7O69r+jokXEsDOwOeBO4HrgQOHXfOAx/9iJv7F8zDwC2DdsGsewjX4KvA/wJru56ph1zzg8X8UWNeN/evAocOuedDXYFLfVcyhu876fA18qHsN3NS9Bg7Z3nP6zQCSpKbm09KZJGkIDBpJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkpoyaCRJTf0fztyuXRFWQfcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "campaign_data['product'].value_counts(normalize=True).plot(\n",
    "    kind='barh', color=clr_dict.values());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the models in PyMC3\n",
    "Now we get into the fun part.  We'll be constructing 3 models here:\n",
    "\n",
    "1) Pooled model: This is the non-hierarchical approach.  We estimate a single $\\alpha$ and a single $\\beta$ for each feature.  For the $\\alpha$ to have meaning, we'll need to include a reference category with each of our features.  The easiest way to do this is to just one-hot encode the features.  In math:\n",
    "\n",
    "\\begin{equation*}\n",
    "Intercept \\sim \\text{Normal}(\\mathit{mu}=0.0, \\mathit{sd}=1.0)\\\\\n",
    "product\\_betas \\sim \\text{Normal}(\\mathit{mu}=0.0, \\mathit{sd}=1.0)\\\\\n",
    "region\\_betas \\sim \\text{Normal}(\\mathit{mu}=0.0, \\mathit{sd}=1.0)\\\\\n",
    "industry\\_betas \\sim \\text{Normal}(\\mathit{mu}=0.0, \\mathit{sd}=1.0)\\\\\n",
    "size\\_betas \\sim \\text{Normal}(\\mathit{mu}=0.0, \\mathit{sd}=1.0)\\\\\n",
    "sigma \\sim \\text{HalfCauchy}(\\mathit{beta}=1)\\\\\n",
    "spend \\sim \\text{Normal}(\\mathit{mu}=f(ind\\_betas,reg\\_betas), \\mathit{sd}=sigma)\\\\\n",
    "\\end{equation*}\n",
    "\n",
    "2) Product-level $\\alpha$: This is where we start getting hierarchical.  In this model, we replace our $\\alpha$ with $\\alpha_p$ for p in {SEO, Email Marketing, SEM, Social, DisplayOnTarget}.  Essentially, a product-level intercept.  These product-level intercepts are drawn from the same distribution with their own set of hyperpriors. \n",
    "\n",
    "\\begin{equation*}\n",
    "mu\\_alpha \\sim \\text{Normal}(\\mathit{mu}=0.0, \\mathit{sd}=1.0)\\\\\n",
    "sigma\\_alpha \\sim \\text{HalfCauchy}(\\mathit{beta}=1)\\\\\n",
    "mu\\_beta \\sim \\text{Normal}(\\mathit{mu}=0.0, \\mathit{sd}=1.0)\\\\\n",
    "sigma\\_beta \\sim \\text{HalfCauchy}(\\mathit{beta}=1)\\\\\n",
    "product\\_alphas \\sim \\text{Normal}(\\mathit{mu}=mu\\_alpha, \\mathit{sd}=sigma\\_alpha)\\\\\n",
    "region\\_betas \\sim \\text{Normal}(\\mathit{mu}=mu\\_beta, \\mathit{sd}=sigma\\_beta)\\\\\n",
    "industry\\_betas \\sim \\text{Normal}(\\mathit{mu}=mu\\_beta, \\mathit{sd}=sigma\\_beta)\\\\\n",
    "size\\_betas \\sim \\text{Normal}(\\mathit{mu}=mu\\_beta, \\mathit{sd}=sigma\\_beta)\\\\\n",
    "sigma \\sim \\text{HalfCauchy}(\\mathit{beta}=1)\\\\\n",
    "spend \\sim \\text{Normal}(\\mathit{mu}=f(ind\\_betas,reg\\_betas), \\mathit{sd}=sigma)\\\\\n",
    "\\end{equation*}\n",
    "\n",
    "3) Product and region-level $\\alpha$: Now we also add another group-level $\\alpha$, $\\alpha_r$ for r in {Northeast, South, Midwest, West}.  We have both product-level and region-level intercepts.  Region-level intercept is drawn from its own distribution, which is separate from both the $\\beta$'s distribution and $\\alpha_p$'s distribution.\n",
    "\n",
    "\\begin{equation*}\n",
    "mu\\_a\\_product \\sim \\text{Normal}(\\mathit{mu}=0.0, \\mathit{sd}=1.0)\\\\\n",
    "sigma\\_a\\_product \\sim \\text{HalfCauchy}(\\mathit{beta}=1)\\\\\n",
    "mu\\_a\\_region \\sim \\text{Normal}(\\mathit{mu}=0.0, \\mathit{sd}=1.0)\\\\\n",
    "sigma\\_a\\_region \\sim \\text{HalfCauchy}(\\mathit{beta}=1)\\\\\n",
    "mu\\_beta \\sim \\text{Normal}(\\mathit{mu}=0.0, \\mathit{sd}=1.0)\\\\\n",
    "sigma\\_beta \\sim \\text{HalfCauchy}(\\mathit{beta}=1)\\\\\n",
    "product\\_alphas \\sim \\text{Normal}(\\mathit{mu}=mu\\_a\\_product, \\mathit{sd}=sigma\\_a\\_product)\\\\\n",
    "region\\_alphas \\sim \\text{Normal}(\\mathit{mu}mu\\_a\\_region, \\mathit{sd}=sigma\\_a\\_region)\\\\\n",
    "industry\\_betas \\sim \\text{Normal}(\\mathit{mu}=mu\\_beta, \\mathit{sd}=sigma\\_beta)\\\\\n",
    "size\\_betas \\sim \\text{Normal}(\\mathit{mu}=mu\\_beta, \\mathit{sd}=sigma\\_beta)\\\\\n",
    "sigma \\sim \\text{HalfCauchy}(\\mathit{beta}=1)\\\\\n",
    "spend \\sim \\text{Normal}(\\mathit{mu}=f(ind\\_betas,reg\\_betas), \\mathit{sd}=sigma)\\\\\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pooled: need dummy variables\n",
    "dummy_dict = {}\n",
    "shared_vars = {}\n",
    "for c in ['product', 'size', 'region', 'industry']:\n",
    "    dummy_dict[c] = pd.get_dummies(campaign_data[c]).iloc[:,1:].values\n",
    "    # setting these as shared variables, will explain later\n",
    "    shared_vars[c] = shared(dummy_dict[c])\n",
    "# additional shared vars\n",
    "shared_vars['product_idx'] = shared(campaign_data.product_idx.values)\n",
    "shared_vars['region_idx'] = shared(campaign_data.region_idx.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, m_name, trace_num=5000, tune=1000, chains=4, display=True):\n",
    "    # utility function for running model, displaying traceplots and diagnostics\n",
    "    with model:\n",
    "        trace = pm.sample(trace_num, tune=tune, chains=chains)[tune:]\n",
    "    if display:\n",
    "        pm.plots.traceplot(trace, combined=True)\n",
    "    return(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "# non-hierarchical / pooled\n",
    "with pm.Model() as model:\n",
    "    product_betas = pm.Normal('product_betas', mu=0., sd=1.0, \n",
    "                              shape=campaign_data['product'].nunique()-1)\n",
    "    size_betas = pm.Normal('size_betas', mu=0., sd=1.0, \n",
    "                           shape=campaign_data['size'].nunique()-1)\n",
    "    region_betas = pm.Normal('region_betas', mu=0., sd=1.0,\n",
    "                             shape=campaign_data['region'].nunique()-1)\n",
    "    industry_betas = pm.Normal('industry_betas', mu=0., sd=1.0,\n",
    "                               shape=campaign_data['industry'].nunique()-1)\n",
    "    intercept = pm.Normal('Intercept', 0., sd=1.0)\n",
    "    sigma = pm.HalfCauchy('sigma', beta=1)\n",
    "    \n",
    "    mu = intercept+pm.math.dot(product_betas, shared_vars['product'].T)+\\\n",
    "        pm.math.dot(size_betas, shared_vars['size'].T)+\\\n",
    "        pm.math.dot(region_betas, shared_vars['region'].T)+\\\n",
    "        pm.math.dot(industry_betas, shared_vars['industry'].T)\n",
    "    mu_pred = pm.Normal('spend', mu=mu, sd=sigma, \n",
    "                        observed=campaign_data['log_billed_amount'])\n",
    "model_dict['pooled'] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 2 jobs)\n",
      "NUTS: [sigma, Intercept, industry_betas, region_betas, size_betas, product_betas]\n",
      "Sampling 4 chains:   1%|         | 128/16000 [5:45:52<761:38:33, 172.75s/draws]"
     ]
    }
   ],
   "source": [
    "trace_dict = {}\n",
    "trace_dict['pooled'] = run_model(model_dict['pooled'], 'pooled', trace_num=3000, tune=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting PyMC3's traceplots\n",
    "Let's break here to take a look at exactly what we're seeing in the plots above.\n",
    "\n",
    "On the right, we're seeing the results of the No U-Turn sampler PyMC3 automatically assigned to our parameters.  As you remember, a sampler draws from the posterior distribution by only \"accepting\" a value if it increases the likelihood of the data.  You can see the movement of that sampler (i.e. the \"trace\") in these plots.  Typically, a good trace will fully explore the probability space and not get stuck in certain areas.  For more information on how to escape these narrowed traces, [read more at Thomas Wiecki's blog](https://twiecki.github.io/blog/2017/02/08/bayesian-hierchical-non-centered).\n",
    "\n",
    "On the left you see our posterior distribution.  We've enforced normal priors here, so it's to be expected that we're seeing a normal distribution returned.  The doubling of the lines you're seeing are from different sampler runs (i.e. \"chains\").  It's good practice to check that the two chains don't differ much from one another.\n",
    "\n",
    "So now let's press ahead with the hiearchical formulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiearchical - product\n",
    "with pm.Model() as model:\n",
    "    # Hyperpriors\n",
    "    mu_a = pm.Normal('mu_alpha', mu=0., sd=1)\n",
    "    sigma_a = pm.HalfCauchy('sigma_alpha', beta=1)\n",
    "    mu_b = pm.Normal('mu_beta', mu=0., sd=1)\n",
    "    sigma_b = pm.HalfCauchy('sigma_beta', beta=1)\n",
    "    \n",
    "    # product-level intercept\n",
    "    product_alphas = pm.Normal('product_alphas', mu=mu_a, sd=sigma_a, \n",
    "                              shape=campaign_data['product'].nunique())\n",
    "    \n",
    "    # betas\n",
    "    region_betas = pm.Normal('region_betas', mu=mu_b, sd=sigma_b,\n",
    "                             shape=campaign_data['region'].nunique()-1)\n",
    "    size_betas = pm.Normal('size_betas', mu=mu_b, sd=sigma_b, \n",
    "                           shape=campaign_data['size'].nunique()-1)\n",
    "    industry_betas = pm.Normal('industry_betas', mu=mu_b, sd=sigma_b,\n",
    "                               shape=campaign_data['industry'].nunique()-1)\n",
    "    sigma = pm.HalfCauchy('sigma', beta=1)\n",
    "    \n",
    "    mu = product_alphas[shared_vars['product_idx']]+\\\n",
    "        pm.math.dot(size_betas, shared_vars['size'].T)+\\\n",
    "        pm.math.dot(region_betas, shared_vars['region'].T)+\\\n",
    "        pm.math.dot(industry_betas, shared_vars['industry'].T)\n",
    "    mu_pred = pm.Normal('spend', mu=mu, sd=sigma, \n",
    "                        observed=campaign_data['log_billed_amount'])\n",
    "model_dict['product_alphas'] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for m in ['product_alphas']:\n",
    "    trace_dict[m] = run_model(model_dict[m], m, trace_num=3000, tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiearchical - product and region\n",
    "with pm.Model() as model:\n",
    "    # Hyperpriors\n",
    "    mu_a_product = pm.Normal('mu_a_product', mu=0., sd=1)\n",
    "    sigma_a_product = pm.HalfCauchy('sigma_a_product', beta=1)\n",
    "    # removed due to poor performance\n",
    "    #mu_a_region = pm.Normal('mu_a_region', mu=0., sd=1)\n",
    "    #sigma_a_region = pm.HalfCauchy('sigma_a_region', beta=1)\n",
    "    mu_b = pm.Normal('mu_beta', mu=0., sd=1)\n",
    "    sigma_b = pm.HalfCauchy('sigma_beta', beta=1)    \n",
    "    \n",
    "    # product and region-level intercepts\n",
    "    product_alphas = pm.Normal('product_alphas', mu=mu_a_product, sd=sigma_a_product, \n",
    "                              shape=campaign_data['product'].nunique())\n",
    "    region_alphas = pm.Normal('region_alphas', mu=0, sd=1.0,\n",
    "                         shape=campaign_data['region'].nunique())\n",
    "    \n",
    "    # betas\n",
    "    size_betas = pm.Normal('size_betas', mu=mu_b, sd=sigma_b, \n",
    "                           shape=campaign_data['size'].nunique()-1)\n",
    "    industry_betas = pm.Normal('industry_betas', mu=mu_b, sd=sigma_b,\n",
    "                               shape=campaign_data['industry'].nunique()-1)\n",
    "    sigma = pm.HalfCauchy('sigma', beta=1)\n",
    "    \n",
    "    mu = product_alphas[shared_vars['product_idx']]+\\\n",
    "        region_alphas[shared_vars['region_idx']]+\\\n",
    "        pm.math.dot(size_betas, shared_vars['size'].T)+\\\n",
    "        pm.math.dot(industry_betas, shared_vars['industry'].T)\n",
    "    mu_pred = pm.Normal('spend', mu=mu, sd=sigma, \n",
    "                        observed=campaign_data['log_billed_amount'])\n",
    "model_dict['product_region_alphas'] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for m in ['product_region_alphas']:\n",
    "    trace_dict[m] = run_model(model_dict[m], m, trace_num=3000, tune=1000, chains=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating hierarchical traceplots\n",
    "Though it varies by run, we will occasionally see a warning about our trace not achieving the \"acceptance probability\" or about the effective sample size.  These are some common warnings that might pop up, so let's discuss them briefly.\n",
    "\n",
    "\n",
    "#### Some common warnings\n",
    "Not achieving acceptance probability: The acceptance probability is the rate at which a sample proposed by the sampler is accepted.  More info on this [here](https://twiecki.github.io/blog/2015/11/10/mcmc-sampling/#Explaining-MCMC-sampling-with-code).  The tuning samples adjust the step sizes to achieve the acceptance probability.  This warning may suggest the need for additional tuning samples or adjusted step sizes.\n",
    "\n",
    "Effective sample size: [Effective sample size](https://en.wikipedia.org/wiki/Effective_sample_size) is the sample size accounting for correlation between observations. MCMC samples are by nature correlated with one another.  If this autocorrelation is particularly high, this reduces the effective sample size.  Both small and large step sizes can contribute to autocorrelation.  Again, this may require additional tuning, specifying a step size or some smart data \"thinning\".\n",
    "\n",
    "#### Examining traceplots\n",
    "From the looks of it, these region-level alphas don't seem to be much different.  Our sense is that they may not be contributing much to the model.  It makes sense, here, to do some model comparison between all three of the models we've run so far and see which we have evidence to move forward with.  For that, we'll be using something called the Widely-Available Information Criterion (see slides)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic_df = pm.compare({model_dict['pooled']:trace_dict['pooled'], \n",
    "            model_dict['product_alphas']:trace_dict['product_alphas'],\n",
    "           model_dict['product_region_alphas']:trace_dict['product_region_alphas']})\n",
    "waic_df.index = ['pooled', 'product_alphas', 'product_region_alphas']\n",
    "waic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the pooled model actually has lower WAIC than either of the hierarchical implementations.  It may be that we need to tweak some of our priors or other parameters in the model in order to really get the value from a hierarchical implementation.  But these numbers are not hugely different from one another and it might make more sense to look at what sort of predictions we're getting out of them before we jump to conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior Predictive Checks\n",
    "Posterior predictive checks are based on the posterior predictive distribution, which are explained in the slides.  PyMC3 allows us to sample from this distribution for \"checks\" on the predictions.  A nice way to do that is to look at a set of these samples compared to the source distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = 'product_alphas'\n",
    "ppc_dict = {}\n",
    "ppcs = pm.sample_ppc(trace_dict[selected_model], model=model_dict[selected_model], samples=1000)['spend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(ppcs.shape)\n",
    "ppcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary for storing product-specific data\n",
    "product_ppcs = {}\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18,10), sharey=True, sharex=True)\n",
    "for i, product in enumerate(campaign_data['product'].unique()):\n",
    "    if i<3:\n",
    "        r = 0\n",
    "        c = i\n",
    "    else:\n",
    "        r = 1\n",
    "        c = i-3\n",
    "    # subset ppcs to just product\n",
    "    # ppcs are formatted (n_samples, n_observations)\n",
    "    product_ppc = ppcs[:, (campaign_data['product']==product).values]\n",
    "    product_ppcs[product] = product_ppc\n",
    "    # get a random selection of samples to plot\n",
    "    rand_samples = np.random.randint(len(ppcs), size=10)\n",
    "    # plot samples\n",
    "    for sample in product_ppc[rand_samples]:\n",
    "        sns.kdeplot(sample, ax=axs[r,c], color=clr_dict[product], alpha=.2)\n",
    "    # plot actual\n",
    "    sns.kdeplot(campaign_data[campaign_data['product']==product]['log_billed_amount'], \n",
    "                ax=axs[r,c], color=clr_dict[product], legend=None)\n",
    "    axs[r,c].set_title(product)\n",
    "fig.delaxes(axs[r, c+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-test for significance of differences\n",
    "There are a number of ways to test how different these sample distributions are from the source distributions.  But a quick method would just be to test the difference in means.  So let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run for each product, take the average t and p values\n",
    "for product in product_ppcs:\n",
    "    print('\\n%s' % product)\n",
    "    t, p = ttest_ind(product_ppcs[product], \n",
    "                     campaign_data[campaign_data['product']==product]['log_billed_amount'])\n",
    "    print('Average t-value: %s' % np.mean(t))\n",
    "    print('Average p-value: %s' % np.mean(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Productionizing\n",
    "Now we come back to why we used shared variables from Theano to set up our models.  Shared variables allow us to change out the data being used in the model.  That allows for functionality like changing data based on a user's query.  Let's mock up a query we might get from an API that contains some customer attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy original shared data\n",
    "original_shared = deepcopy(shared_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query_json):\n",
    "    # subsetting data to customers specified in query\n",
    "    subset_data = campaign_data.query('&'.join([\"({}=='{}')\".format(k,v) for k,v in customer_query.items()]))\n",
    "    for c in shared_vars.keys():\n",
    "        shared_vars[c].set_value(original_shared[c].get_value()[subset_data.index])\n",
    "    # run ppcs\n",
    "    query_ppcs = pm.sample_ppc(trace_dict[selected_model], model=model_dict[selected_model], samples=100)['spend']\n",
    "    # create data for histogram\n",
    "    ppc_series = pd.Series(np.median(query_ppcs, axis=1)).copy(deep=True)\n",
    "    # converting to dollars (simple transformation)\n",
    "    ppc_series = np.exp(ppc_series)\n",
    "    return(ppc_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mocking a customer query\n",
    "customer_query = {'product':'Display', 'region':'northeast', 'industry': 'fullservice_restaurants'}\n",
    "display_ppc = run_query(customer_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now what if that customer was interested in SEM?\n",
    "customer_query.update({'product':'SEM'})\n",
    "sem_ppc = run_query(customer_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, sharey=True, sharex=False)\n",
    "display_ppc.plot(kind='hist', ax=axs[0], title='Display spend')\n",
    "sem_ppc.plot(kind='hist', ax=axs[1], title='SEM spend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
